{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sarp.utils import load_expert_data_hospital, separate_train_test, combine_nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)],\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "currn_dir = os.path.dirname(os.path.abspath(\"2_sarp_repair.ipynb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an example of policy repair using SARP for the robot navigation in hospital. This script assumes that a pre-trained policy and a predictive model are already available. To pre-train a policy for this example run [0_pretrain_policy.py](0_pretrain_policy.py). Also to train a predictive model run [1_pretrain_predictive_model.py](1_pretrain_predictive_model.py). Here are the descriptions of models:\n",
    "- policy - input: the system state that includes the robot's goal, distancc and heading toward goal, and range sensor readings - output: linear and angular velocities.\n",
    "- predictive model - input: states and actions - output: collision [0, 1] or no collision [1, 0]."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laod dataset\n",
    "First, we load the expert demonstrations for repair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading sample 1, goal: [10. 10.]\n",
      "loading sample 2, goal: [10. 10.]\n",
      "loading sample 3, goal: [10. 10.]\n",
      "loading sample 4, goal: [10. 10.]\n",
      "loading sample 5, goal: [10. 10.]\n",
      "loading sample 6, goal: [10. 10.]\n",
      "loading sample 7, goal: [10. 10.]\n",
      "loading sample 8, goal: [10. 10.]\n",
      "loading sample 9, goal: [10. 10.]\n",
      "loading sample 10, goal: [10. 10.]\n",
      "loading sample 11, goal: [-10.   5.]\n",
      "loading sample 12, goal: [-10.   5.]\n",
      "loading sample 13, goal: [-10.   5.]\n",
      "loading sample 14, goal: [-10.   5.]\n",
      "loading sample 15, goal: [-10.   5.]\n",
      "loading sample 16, goal: [-10.   5.]\n",
      "loading sample 17, goal: [-10.   5.]\n",
      "loading sample 18, goal: [-10.   5.]\n",
      "loading sample 19, goal: [-10.   5.]\n",
      "loading sample 20, goal: [-10.   5.]\n",
      "loading sample 21, goal: [10.  5.]\n",
      "loading sample 22, goal: [10.  5.]\n",
      "loading sample 23, goal: [10.  5.]\n",
      "loading sample 24, goal: [10.  5.]\n",
      "loading sample 25, goal: [10.  5.]\n",
      "loading sample 26, goal: [10.  5.]\n",
      "loading sample 27, goal: [10.  5.]\n",
      "loading sample 28, goal: [10.  5.]\n",
      "loading sample 29, goal: [10.  5.]\n",
      "loading sample 30, goal: [10.  5.]\n",
      "loading sample 31, goal: [-9. -9.]\n",
      "loading sample 32, goal: [-9. -9.]\n",
      "loading sample 33, goal: [-9. -9.]\n",
      "loading sample 34, goal: [-9. -9.]\n",
      "loading sample 35, goal: [-9. -9.]\n",
      "loading sample 36, goal: [-9. -9.]\n",
      "loading sample 37, goal: [-9. -9.]\n",
      "loading sample 38, goal: [-9. -9.]\n",
      "loading sample 39, goal: [-9. -9.]\n",
      "loading sample 40, goal: [-9. -9.]\n",
      "loading sample 41, goal: [ 9. -9.]\n",
      "loading sample 42, goal: [ 9. -9.]\n",
      "loading sample 43, goal: [ 9. -9.]\n",
      "loading sample 44, goal: [ 9. -9.]\n",
      "loading sample 45, goal: [ 9. -9.]\n",
      "loading sample 46, goal: [ 9. -9.]\n",
      "loading sample 47, goal: [ 9. -9.]\n",
      "loading sample 48, goal: [ 9. -9.]\n",
      "loading sample 49, goal: [ 9. -9.]\n",
      "loading sample 50, goal: [ 9. -9.]\n",
      "loading sample 51, goal: [-10.  10.]\n",
      "loading sample 52, goal: [-10.  10.]\n",
      "loading sample 53, goal: [-10.  10.]\n",
      "loading sample 54, goal: [-10.  10.]\n",
      "loading sample 55, goal: [-10.  10.]\n",
      "loading sample 56, goal: [-10.  10.]\n",
      "loading sample 57, goal: [-10.  10.]\n",
      "loading sample 58, goal: [-10.  10.]\n",
      "loading sample 59, goal: [-10.  10.]\n",
      "loading sample 60, goal: [-10.  10.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:17:23.614112: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-04 15:17:24.224483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5120 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:d5:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# load the expert data\n",
    "data_dir = currn_dir + f\"/data/expert_data\"\n",
    "num_samples = len(os.listdir(data_dir))\n",
    "\n",
    "state, action, _, property = load_expert_data_hospital(data_dir, num_samples)\n",
    "state = [tf.convert_to_tensor(s, dtype=tf.float32) for s in state]\n",
    "action = [tf.convert_to_tensor(a, dtype=tf.float32) for a in action]\n",
    "property = [tf.convert_to_tensor(p, dtype=tf.float32) for p in property]\n",
    "train_data, test_data = separate_train_test([state, action, property], test_ratio=0.2)\n",
    "\n",
    "state_train, action_train, property_train = train_data\n",
    "state_test, action_test, property_test = test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and megre models\n",
    "Here, we load the policy and predictive models, then we merge them in a series fashion to be used in repair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"repair_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " policy_layer_1 (Dense)      multiple                  3840      \n",
      "                                                                 \n",
      " policy_layer_2 (Dense)      multiple                  65792     \n",
      "                                                                 \n",
      " policy_layer_3 (Dense)      multiple                  514       \n",
      "                                                                 \n",
      " Predictive_layer_1 (Dense)  multiple                  4352      \n",
      "                                                                 \n",
      " Predictive_layer_2 (Dense)  multiple                  65792     \n",
      "                                                                 \n",
      " Predictive_layer_3 (Dense)  multiple                  2570      \n",
      "                                                                 \n",
      " Predictive_layer_4 (Dense)  multiple                  1408      \n",
      "                                                                 \n",
      " Predictive_layer_5 (Dense)  multiple                  16512     \n",
      "                                                                 \n",
      " Predictive_layer_6 (Dense)  multiple                  258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,038\n",
      "Trainable params: 161,038\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the models\n",
    "model_policy_orig = keras.models.load_model(\n",
    "    currn_dir\n",
    "    + f\"/trained_models/policy/model\"\n",
    "    )\n",
    "model_predictive = keras.models.load_model(\n",
    "    currn_dir\n",
    "    + f\"/trained_models/predictive_model/model\"\n",
    "    )\n",
    "\n",
    "# combine the models\n",
    "model_combined = combine_nets(model_policy_orig, model_predictive)\n",
    "\n",
    "# keep only the policy part of the combined model to be trained\n",
    "for layer in model_combined.layers:\n",
    "    if layer.name.split(\"_\")[0] == \"policy\":\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "_,_ = model_combined.predict(state[0][0:1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the optimization parameters\n",
    "\n",
    "We first define the loss function, lagrangian penalty terms and the quadratic penalty terms. We assum two constraints:\n",
    "1. Constraint on linear velocity: $v\\leq0.9$\n",
    "2. Constraint on the output collision property: $\\psi = [1,0]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization parameters\n",
    "learning_rate = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_loss(y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "def col_penalty(y):\n",
    "    return tf.reduce_sum(tf.square(y[:, 1]))\n",
    "\n",
    "def col_lagrangian(y):\n",
    "    return tf.reduce_sum(y[:, 1])\n",
    "\n",
    "def vel_penalty(y):\n",
    "    return tf.reduce_sum(tf.square(tf.nn.relu(y[:, 0] - 0.9)))\n",
    "\n",
    "def vel_lagrangian(y):\n",
    "    return tf.reduce_sum(tf.nn.relu(y[:, 0] - 0.9))\n",
    "\n",
    "def augmented_loss(\n",
    "    s, a, params\n",
    "):\n",
    "    a_pred, p_pred = model_combined(s)\n",
    "    return (\n",
    "        100 * original_loss(a, a_pred)\n",
    "        - params[0] * col_lagrangian(p_pred)\n",
    "        + params[1] / 2 * col_penalty(p_pred)\n",
    "        - params[2] * vel_lagrangian(a_pred)\n",
    "        + params[3] / 2 * vel_penalty(a_pred)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the optimizer and the policy update step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "@tf.function\n",
    "def train_step(\n",
    "    s, a, params\n",
    "):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = augmented_loss(\n",
    "            s, a, params\n",
    "        )\n",
    "    grads = tape.gradient(loss_value, model_combined.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model_combined.trainable_variables))\n",
    "    return loss_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
